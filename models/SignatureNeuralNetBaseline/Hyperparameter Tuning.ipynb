{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import modify_metadata, TARGETS\n",
    "from input_utils import TrainDataset\n",
    "from model import EnsembleModel\n",
    "from training import train, CV_score\n",
    "import matplotlib.pyplot as plt\n",
    "from ax.service.managed_loop import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_METADATA_DIR = \"../../data/train.csv\"\n",
    "TRAIN_SIGNATURES_DIR = \"../../data/train_signatures/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = pd.read_csv(TRAIN_METADATA_DIR)\n",
    "train_metadata = modify_metadata(train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = torch.nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "scaler_types = [\"meanvar_1.0\"]\n",
    "logsigs_or_sigs_types = [\"sigs\"]\n",
    "signature_level = [4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {\"name\": \"scaler_type\", \"type\": \"choice\", \"values\": scaler_types, \"is_ordered\": False},\n",
    "    {\"name\": \"logsigs_or_sigs\", \"type\": \"choice\", \"values\": logsigs_or_sigs_types, \"is_ordered\": False},\n",
    "    {\"name\": \"signature_level\", \"type\": \"choice\", \"values\": signature_level, \"is_ordered\": True},\n",
    "    {\"name\": \"lr\", \"type\": \"range\", \"bounds\": [1e-4, 1e-3]},\n",
    "    {\"name\": \"weight_decay\", \"type\": \"range\", \"bounds\": [1e-5, 1e-3]},\n",
    "    {\"name\": \"dropout\", \"type\": \"choice\", \"values\": [0.5], \"is_ordered\": True},\n",
    "    {\"name\": \"early_stopping_epochs\", \"type\": \"range\", \"bounds\": [40, 50]},\n",
    "    {\"name\": \"classifier_input_dim\", \"type\": \"choice\", \"values\": [128, 256, 512], \"is_ordered\": True},\n",
    "    {\"name\": \"hidden_layer_dim\", \"type\": \"choice\", \"values\": [128, 256, 512], \"is_ordered\": True},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log file for all experiments and CV scores\n",
    "log_file = \"hyperparameter_search_log.csv\"\n",
    "if not os.path.exists(log_file):\n",
    "    with open(log_file, \"w\") as f:\n",
    "        f.write(\"scaler_type,logsigs_or_sigs,signature_level,lr,weight_decay,dropout,early_stopping_epochs,classifier_input_dim,hidden_layer_dim,CV_score\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(parameters):\n",
    "    scaler_type = parameters.get(\"scaler_type\")\n",
    "    logsigs_or_sigs = parameters.get(\"logsigs_or_sigs\")\n",
    "    signature_level = parameters.get(\"signature_level\")\n",
    "\n",
    "    TRAIN_SIGNATURES_FILE = f\"{TRAIN_SIGNATURES_DIR}all_{logsigs_or_sigs}_lvl_{signature_level}_scaler_{scaler_type}_experts_augmented.pt\"\n",
    "    signature_features = torch.load(TRAIN_SIGNATURES_FILE)\n",
    "    dataset = TrainDataset(train_metadata, signature_features)\n",
    "    scores, train_losses, test_losses = CV_score(dataset, parameters.get(\"lr\"), parameters.get(\"weight_decay\"), parameters.get(\"dropout\"), parameters.get(\"classifier_input_dim\"), parameters.get(\"hidden_layer_dim\"), device, criterion, parameters.get(\"early_stopping_epochs\"))\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(f\"{scaler_type},{logsigs_or_sigs},{signature_level},{parameters.get('lr')},{parameters.get('weight_decay')},{parameters.get('dropout')},{parameters.get('early_stopping_epochs')},{parameters.get('classifier_input_dim')},{parameters.get('hidden_layer_dim')},{np.mean(scores)}\\n\")\n",
    "    return -np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters, values, experiment, model = optimize(\n",
    "    parameters=parameters,\n",
    "    evaluation_function=eval_function,\n",
    "    objective_name='CV_score',\n",
    "    total_trials=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_parameters)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_level = 4\n",
    "lr = 0.0006365430731326342\n",
    "weight_decay = 0.00016552539309486747\n",
    "dropout = 0.5\n",
    "early_stopping_epochs = 12\n",
    "classifier_input_dim = 512\n",
    "scaler_type = \"meanvar_1.0\"\n",
    "logsigs_or_sigs = \"sigs\"\n",
    "hidden_layer_dim = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_function({\"scaler_type\": scaler_type, \"logsigs_or_sigs\": logsigs_or_sigs, \"signature_level\": signature_level, \"lr\": lr, \"weight_decay\": weight_decay, \"dropout\": dropout, \"early_stopping_epochs\": early_stopping_epochs, \"classifier_input_dim\": classifier_input_dim, \"hidden_layer_dim\": hidden_layer_dim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
